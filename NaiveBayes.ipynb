{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUJewck3AzoSxNumjQ4DYK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SadiyaMayat/NLP/blob/main/NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "uBSIM85M5oj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6EMIkFu6UJP",
        "outputId": "c789fac0-9303-4b60-bd15-d703c46bc009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your dataset\n",
        "file_path = 'IMDB Dataset.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Display summary statistics of the dataset\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaCDMrhwsbDJ",
        "outputId": "2ef804d6-ae61-4a2c-e2f1-d9832ab2a743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n",
            "None\n",
            "\n",
            "Summary Statistics:\n",
            "                                                   review sentiment\n",
            "count                                               50000     50000\n",
            "unique                                              49582         2\n",
            "top     Loved today's show!!! It was a variety and not...  positive\n",
            "freq                                                    5     25000\n",
            "\n",
            "Missing Values:\n",
            "review       0\n",
            "sentiment    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the lemmatizer and stopwords list\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(text)\n",
        "    # Remove stopwords and lemmatize the words\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    # Join the words back into a single string\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply the preprocessing function to the review column\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Convert sentiment column to numerical labels\n",
        "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Display the first few rows of the cleaned dataset with numerical labels\n",
        "print(\"First few rows of the cleaned dataset with numerical labels:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsEaFgBRvia9",
        "outputId": "ffaa03c8-5dc6-4175-e3fa-e18b45011196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the cleaned dataset with numerical labels:\n",
            "                                              review sentiment  \\\n",
            "0  One of the other reviewers has mentioned that ...  positive   \n",
            "1  A wonderful little production. <br /><br />The...  positive   \n",
            "2  I thought this was a wonderful way to spend ti...  positive   \n",
            "3  Basically there's a family where a little boy ...  negative   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
            "\n",
            "                                      cleaned_review  label  \n",
            "0  one reviewer mentioned watching 1 oz episode y...      1  \n",
            "1  wonderful little production filming technique ...      1  \n",
            "2  thought wonderful way spend time hot summer we...      1  \n",
            "3  basically there family little boy jake think t...      0  \n",
            "4  petter matteis love time money visually stunni...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to top 5000 features\n",
        "\n",
        "# Fit and transform the cleaned review texts\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
        "\n",
        "# Display the shape of the TF-IDF features\n",
        "print(\"Shape of TF-IDF features:\", tfidf_features.shape)\n",
        "\n",
        "# Convert TF-IDF features to a DataFrame for inspection\n",
        "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the TF-IDF features\n",
        "print(\"First few rows of TF-IDF features:\")\n",
        "print(tfidf_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYfVyIOjxwht",
        "outputId": "55f481fa-f06f-4ffa-fecd-47e2599204ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF features: (50000, 5000)\n",
            "First few rows of TF-IDF features:\n",
            "         10  100  1000  1010   11  110   12   13  13th   14  ...  youd  \\\n",
            "0  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
            "1  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
            "2  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
            "3  0.079199  0.0   0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
            "4  0.000000  0.0   0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
            "\n",
            "     youll     young  younger     youre  youth  youve  zero   zombie  zone  \n",
            "0  0.05819  0.000000      0.0  0.000000    0.0    0.0   0.0  0.00000   0.0  \n",
            "1  0.00000  0.000000      0.0  0.000000    0.0    0.0   0.0  0.00000   0.0  \n",
            "2  0.00000  0.080393      0.0  0.000000    0.0    0.0   0.0  0.00000   0.0  \n",
            "3  0.00000  0.000000      0.0  0.081945    0.0    0.0   0.0  0.11441   0.0  \n",
            "4  0.00000  0.000000      0.0  0.000000    0.0    0.0   0.0  0.00000   0.0  \n",
            "\n",
            "[5 rows x 5000 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, df['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Display the shapes of the training and testing sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu6sEvZIyrcX",
        "outputId": "4344c11a-30d5-44f2-b757-700a36f268aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (35000, 5000)\n",
            "Shape of X_test: (15000, 5000)\n",
            "Shape of y_train: (35000,)\n",
            "Shape of y_test: (15000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Train the classifier on the training set\n",
        "nb_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Tmy0G8vK1vl9",
        "outputId": "524625fc-963e-4c16-8b47-849769e58ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels on the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Generate a confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYTXEzg_2ish",
        "outputId": "f0a2fe2f-8f1b-4dda-9be5-84c4085806ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.85\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      7411\n",
            "           1       0.85      0.86      0.85      7589\n",
            "\n",
            "    accuracy                           0.85     15000\n",
            "   macro avg       0.85      0.85      0.85     15000\n",
            "weighted avg       0.85      0.85      0.85     15000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6276 1135]\n",
            " [1085 6504]]\n"
          ]
        }
      ]
    }
  ]
}